# DLMDSEDE02 DataEngineering Phase3 Submission

## ğŸ“Œ Project Overview
This project is the **Phase 3 submission** for the IU course **DLMDSEDE02 â€“ Data Engineering**.  
The goal is to design and implement a **batch-processing data architecture** for machine learning applications, integrating **HDFS, Spark, PostgreSQL, Airflow, Kafka, and Superset**.

---

## âš™ï¸ Tech Stack
- **Hadoop (HDFS)** â€“ Distributed storage
- **Apache Spark** â€“ Batch data processing
- **PostgreSQL** â€“ Data warehouse / storage
- **Apache Airflow** â€“ Workflow orchestration
- **Apache Kafka** â€“ Streaming and messaging backbone
- **Apache Superset** â€“ Data visualization & dashboards
- **Docker & Docker Compose** â€“ Containerization & deployment

---

## ğŸ“‚ Repository Structure
```
DLMDSEDE02_DataEngineering_Phase3Submission/
â”œâ”€â”€ airflow/              # Airflow DAGs and configs
â”œâ”€â”€ app/                  # Spark application code
â”œâ”€â”€ datasets/             # Input datasets (e.g., taxi_zone_lookup.csv)
â”œâ”€â”€ scripts/              # Utility scripts
â”œâ”€â”€ sql/                  # SQL initialization scripts for PostgreSQL
â”œâ”€â”€ docker-compose.yml    # Multi-service orchestration file
â””â”€â”€ README.md             # Project documentation
```

---

## ğŸš€ Setup Instructions

### 1. Clone the repository
```bash
git clone https://github.com/kasaralavamsi/DataEngineering-DLMDSEDE02.git
cd DLMDSEDE02_DataEngineering_Phase3Submission
```

### 2. Start the environment
```bash
docker compose up -d
```

### 3. Load datasets into HDFS
```bash
docker compose exec namenode hdfs dfs -mkdir -p /datasets
docker compose exec namenode hdfs dfs -put -f /datasets/taxi_zone_lookup.csv /datasets/
```

### 4. Verify PostgreSQL ingestion
```bash
docker compose exec -T postgres psql -U nyc -d nyc -c "SELECT * FROM taxi_zone_lookup LIMIT 5;"
```

### 5. Run Spark job
```bash
docker compose exec spark-master bash -lc "/spark/bin/spark-submit --master 'local[*]' /opt/spark/app/spark_job.py"
```

---

## ğŸ“Š Visualization
Once data pipelines are executed, Superset can be accessed at:

ğŸ‘‰ [http://localhost:8089](http://localhost:8089)

---

## ğŸ‘¤ Author
**Vamshi Krishna Kasarla**  
IU MSc Data Science â€“ DLMDSEDE02 (Data Engineering)  
